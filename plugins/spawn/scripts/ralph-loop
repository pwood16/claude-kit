#!/usr/bin/env -S uv run --script
# /// script
# requires-python = ">=3.10"
# dependencies = []
# ///
"""
ralph-loop - Run a Ralph Wiggum loop on a spec file.

Iteratively runs claude -p to work through spec tasks until complete.
Supports two spec formats:
  1. Markdown specs with "## Step by Step Tasks" section (h3 headers as tasks)
  2. JSON PRD files with a "stories" array (legacy format)

Exits when: all tasks complete, max-iterations reached, or completion promise detected.

Usage:
    ralph-loop --spec <file> [--max-iterations N] [--completion-promise TEXT]
    ralph-loop --prd <file> [--max-iterations N] [--completion-promise TEXT]  (legacy JSON format)

Examples:
    ralph-loop --spec specs/feature.md
    ralph-loop --spec specs/feature.json --max-iterations 10
    ralph-loop --prd legacy.json --completion-promise "ALL DONE"
"""

import argparse
import json
import os
import re
import subprocess
import sys
import tempfile
import time
from datetime import datetime
from pathlib import Path
from typing import Optional


def log(step: str, message: str) -> None:
    """Log a message with step indicator."""
    print(f"[{step}] {message}", flush=True)


# ============================================================================
# Output Formatting Utilities
# ============================================================================

def supports_color() -> bool:
    """
    Check if terminal supports ANSI color codes.

    Returns: True if colors should be used, False otherwise
    """
    # Check if stdout is a terminal
    if not hasattr(sys.stdout, "isatty") or not sys.stdout.isatty():
        return False

    # Check TERM environment variable
    term = os.environ.get("TERM", "")
    if term == "dumb":
        return False

    return True


# Color code constants
_USE_COLOR = supports_color()
GREEN = "\033[32m" if _USE_COLOR else ""
YELLOW = "\033[33m" if _USE_COLOR else ""
RED = "\033[31m" if _USE_COLOR else ""
BLUE = "\033[34m" if _USE_COLOR else ""
RESET = "\033[0m" if _USE_COLOR else ""


def format_separator(char: str = "=", width: int = 70) -> str:
    """
    Create a visual divider line.

    Args:
        char: Character to repeat (default: "=")
        width: Width of the separator (default: 70)

    Returns: String of repeated characters
    """
    return char * width


def format_timestamp(dt: Optional[datetime] = None) -> str:
    """
    Format a timestamp for consistent display.

    Args:
        dt: Datetime object (default: now)

    Returns: Formatted timestamp string (YYYY-MM-DD HH:MM:SS)
    """
    if dt is None:
        dt = datetime.now()
    return dt.strftime("%Y-%m-%d %H:%M:%S")


def format_iteration_summary(
    iteration: int,
    spec_format: str,
    task_title: str,
    task_status: str,
    files_added: list[str],
    files_modified: list[str],
    files_deleted: list[str],
    exit_code: int,
    total_tasks: int,
    completed_tasks: int
) -> str:
    """
    Format an iteration summary with structured data.

    Args:
        iteration: Iteration number
        spec_format: "json" or "markdown"
        task_title: Title of the task being worked on
        task_status: "complete" or "incomplete"
        files_added: List of newly added files
        files_modified: List of modified files
        files_deleted: List of deleted files
        exit_code: Exit code of the iteration (0 = success)
        total_tasks: Total number of tasks in spec
        completed_tasks: Number of completed tasks

    Returns: Formatted summary string
    """
    lines = []
    timestamp = format_timestamp()

    # Header separator
    lines.append(format_separator("="))
    lines.append(f"Iteration {iteration} Summary - {timestamp}")
    lines.append(format_separator("="))
    lines.append("")

    # Task being worked on
    lines.append(f"Task: {task_title}")
    lines.append("")

    # Task status (color-coded)
    if task_status == "complete":
        status_text = f"{GREEN}✓ Complete{RESET}"
    else:
        status_text = f"{YELLOW}○ Incomplete{RESET}"
    lines.append(f"Status: {status_text}")
    lines.append("")

    # Files changed
    total_file_changes = len(files_added) + len(files_modified) + len(files_deleted)
    if total_file_changes == 0:
        lines.append("Files changed: None")
    else:
        lines.append(f"Files changed: {total_file_changes}")

        if files_added:
            lines.append(f"  {GREEN}Added ({len(files_added)}){RESET}:")
            for f in files_added[:5]:  # Limit to first 5
                lines.append(f"    + {f}")
            if len(files_added) > 5:
                lines.append(f"    ... and {len(files_added) - 5} more")

        if files_modified:
            lines.append(f"  {BLUE}Modified ({len(files_modified)}){RESET}:")
            for f in files_modified[:5]:  # Limit to first 5
                lines.append(f"    ~ {f}")
            if len(files_modified) > 5:
                lines.append(f"    ... and {len(files_modified) - 5} more")

        if files_deleted:
            lines.append(f"  {RED}Deleted ({len(files_deleted)}){RESET}:")
            for f in files_deleted[:5]:  # Limit to first 5
                lines.append(f"    - {f}")
            if len(files_deleted) > 5:
                lines.append(f"    ... and {len(files_deleted) - 5} more")

    lines.append("")

    # Exit status
    if exit_code == 0:
        exit_status = f"{GREEN}Success{RESET}"
    else:
        exit_status = f"{RED}Failed (exit code: {exit_code}){RESET}"
    lines.append(f"Exit status: {exit_status}")
    lines.append("")

    # Progress
    lines.append(f"Progress: {completed_tasks} of {total_tasks} tasks complete")
    lines.append("")

    # Footer separator
    lines.append(format_separator("="))

    return "\n".join(lines)


# ============================================================================
# Git Change Tracking Utilities
# ============================================================================

def get_git_status() -> dict[str, list[str]]:
    """
    Get current git status and parse into added/modified/deleted file lists.

    Returns: Dict with keys "added", "modified", "deleted" containing file paths
    """
    try:
        result = subprocess.run(
            ["git", "status", "--porcelain"],
            capture_output=True,
            text=True,
            check=True
        )
    except subprocess.CalledProcessError:
        # Not a git repo or git error - return empty lists
        return {"added": [], "modified": [], "deleted": []}

    added = []
    modified = []
    deleted = []

    for line in result.stdout.strip().split("\n"):
        if not line:
            continue

        # Git status --porcelain format:
        # XY FILENAME
        # X = status in index, Y = status in working tree
        # A = added, M = modified, D = deleted, ? = untracked
        status = line[:2]
        filepath = line[3:]

        if "?" in status or "A" in status:
            added.append(filepath)
        elif "M" in status:
            modified.append(filepath)
        elif "D" in status:
            deleted.append(filepath)

    return {"added": added, "modified": modified, "deleted": deleted}


def diff_file_changes(
    before: dict[str, list[str]],
    after: dict[str, list[str]]
) -> dict[str, list[str]]:
    """
    Compute the delta between before/after git status.

    Args:
        before: Git status before iteration
        after: Git status after iteration

    Returns: Dict with keys "added", "modified", "deleted" showing new changes
    """
    # Convert lists to sets for easier comparison
    before_added = set(before["added"])
    before_modified = set(before["modified"])
    before_deleted = set(before["deleted"])

    after_added = set(after["added"])
    after_modified = set(after["modified"])
    after_deleted = set(after["deleted"])

    # Compute differences
    newly_added = list(after_added - before_added)
    newly_modified = list(after_modified - before_modified)
    newly_deleted = list(after_deleted - before_deleted)

    return {
        "added": newly_added,
        "modified": newly_modified,
        "deleted": newly_deleted
    }


# ============================================================================
# Task Extraction Utilities
# ============================================================================

def get_markdown_tasks(spec_file: Path) -> list[tuple[str, str]]:
    """
    Extract all tasks from a Markdown spec with their status.

    Returns: List of (title, status) tuples where status is "complete" or "incomplete"
    """
    content = spec_file.read_text()
    lines = content.split("\n")

    in_tasks = False
    tasks = []
    current_task = None
    prev_was_h3 = False

    for line in lines:
        # Check for entering Step by Step Tasks section
        if line.startswith("## Step by Step Tasks"):
            in_tasks = True
            continue

        # Check for exiting section (hit another h2)
        if in_tasks and line.startswith("## ") and not line.startswith("## Step by Step Tasks"):
            break

        if in_tasks:
            if line.startswith("### "):
                # Extract task title (remove ### prefix)
                title = line[4:].strip()
                current_task = title
                tasks.append((title, "incomplete"))
                prev_was_h3 = True
            elif prev_was_h3:
                # Check if this line marks completion
                if "**Status:**" in line and "complete" in line.lower():
                    # Update the last task's status
                    if tasks:
                        tasks[-1] = (tasks[-1][0], "complete")
                prev_was_h3 = False

    return tasks


def get_json_stories(spec_file: Path) -> list[tuple[str, str, str]]:
    """
    Extract all stories from a JSON spec with their status.

    Returns: List of (story_id, title, status) tuples
    """
    try:
        content = spec_file.read_text()
        data = json.loads(content)
    except (json.JSONDecodeError, OSError):
        return []

    stories = data.get("stories", [])
    result = []

    for story in stories:
        story_id = story.get("id", "")
        title = story.get("title", "Untitled")
        status = story.get("status", "").lower()

        # Normalize status
        if status in ("complete", "done"):
            normalized_status = "complete"
        else:
            normalized_status = "incomplete"

        result.append((story_id, title, normalized_status))

    return result


def find_current_task(tasks: list[tuple]) -> Optional[tuple]:
    """
    Find the first incomplete task from a list of tasks.

    Args:
        tasks: List of task tuples (format depends on spec type)
               For markdown: (title, status)
               For json: (story_id, title, status)

    Returns: The first incomplete task tuple, or None if all complete
    """
    for task in tasks:
        # Status is always the last element in the tuple
        status = task[-1]
        if status == "incomplete":
            return task

    return None


def generate_iteration_summary(
    iteration: int,
    spec_format: str,
    spec_file: Path,
    file_changes: dict[str, list[str]],
    exit_code: int
) -> str:
    """
    Generate a complete iteration summary by gathering task info and formatting it.

    Args:
        iteration: Iteration number
        spec_format: "json" or "markdown"
        spec_file: Path to spec file
        file_changes: Dict with "added", "modified", "deleted" file lists
        exit_code: Exit code of the iteration

    Returns: Formatted summary string
    """
    # Get all tasks
    if spec_format == "json":
        tasks = get_json_stories(spec_file)
    else:
        tasks = get_markdown_tasks(spec_file)

    # Calculate progress
    total_tasks = len(tasks)
    completed_tasks = sum(1 for task in tasks if task[-1] == "complete")

    # Find current task (the one that was just worked on)
    # We look for the most recently completed task, or the first incomplete one
    current_task = None
    task_status = "incomplete"

    # Try to find the last completed task (assuming it was just completed this iteration)
    for task in reversed(tasks):
        if task[-1] == "complete":
            current_task = task
            task_status = "complete"
            break

    # If no complete tasks, find the first incomplete one
    if current_task is None:
        current_task = find_current_task(tasks)
        if current_task:
            task_status = "incomplete"

    # Extract task title based on format
    if current_task:
        if spec_format == "json":
            # Format: (story_id, title, status)
            task_title = current_task[1]
        else:
            # Format: (title, status)
            task_title = current_task[0]
    else:
        task_title = "Unknown task"

    # Format and return summary
    return format_iteration_summary(
        iteration=iteration,
        spec_format=spec_format,
        task_title=task_title,
        task_status=task_status,
        files_added=file_changes["added"],
        files_modified=file_changes["modified"],
        files_deleted=file_changes["deleted"],
        exit_code=exit_code,
        total_tasks=total_tasks,
        completed_tasks=completed_tasks
    )


def parse_arguments() -> argparse.Namespace:
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(
        description="Run a Ralph Wiggum loop on a spec file",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Supports two spec formats:
  1. Markdown specs with "## Step by Step Tasks" section (h3 headers as tasks)
  2. JSON PRD files with a "stories" array (legacy format)

Examples:
    %(prog)s --spec specs/feature.md
    %(prog)s --spec specs/feature.json --max-iterations 10
    %(prog)s --prd legacy.json --completion-promise "ALL DONE"
        """
    )

    # Create mutually exclusive group for --spec and --prd (both do the same thing)
    spec_group = parser.add_mutually_exclusive_group(required=True)
    spec_group.add_argument(
        "--spec",
        dest="spec_file",
        help="Path to spec file (Markdown or JSON)"
    )
    spec_group.add_argument(
        "--prd",
        dest="spec_file",
        help="Path to spec file (legacy alias for --spec)"
    )

    parser.add_argument(
        "--max-iterations",
        type=int,
        default=0,
        help="Maximum iterations (0 = unlimited, default: 0)"
    )
    parser.add_argument(
        "--completion-promise",
        default="TASK COMPLETE",
        help='String to detect completion (default: "TASK COMPLETE")'
    )
    parser.add_argument(
        "--summary-only",
        action="store_true",
        help="Show only iteration summaries, suppress verbose Claude output"
    )
    parser.add_argument(
        "--no-summaries",
        action="store_true",
        help="Disable iteration summaries (for backwards compatibility)"
    )

    args = parser.parse_args()

    # Validate spec file exists
    spec_path = Path(args.spec_file)
    if not spec_path.exists():
        parser.error(f"Spec file not found: {args.spec_file}")

    if not spec_path.is_file():
        parser.error(f"Spec path is not a file: {args.spec_file}")

    return args


def detect_spec_format(spec_file: Path) -> str:
    """
    Detect spec format based on file extension and content.

    Returns: "json" or "markdown"
    Raises: ValueError if format cannot be determined
    """
    # Check file extension first
    suffix = spec_file.suffix.lower()

    if suffix == ".json":
        return "json"
    elif suffix == ".md":
        return "markdown"

    # Try to auto-detect based on content
    content = spec_file.read_text()

    # Try parsing as JSON
    try:
        data = json.loads(content)
        if isinstance(data, dict) and "stories" in data:
            return "json"
    except json.JSONDecodeError:
        pass

    # Check for markdown markers
    if re.search(r"^## Step by Step Tasks", content, re.MULTILINE):
        return "markdown"

    raise ValueError(
        f"Could not detect spec format for: {spec_file}\n"
        "Use .json or .md extension, or ensure the file contains "
        "a 'stories' array (JSON) or '## Step by Step Tasks' section (Markdown)."
    )


def validate_json_spec(spec_file: Path) -> None:
    """
    Validate that a JSON spec file has a 'stories' array.

    Raises: ValueError if validation fails
    """
    try:
        content = spec_file.read_text()
        data = json.loads(content)
    except json.JSONDecodeError as e:
        raise ValueError(f"Invalid JSON in spec file: {e}")

    if not isinstance(data, dict):
        raise ValueError("JSON spec must be an object with a 'stories' array")

    if "stories" not in data:
        raise ValueError("JSON spec must have a 'stories' array")

    if not isinstance(data["stories"], list):
        raise ValueError("'stories' must be an array")


def validate_markdown_spec(spec_file: Path) -> None:
    """
    Validate that a Markdown spec file has a '## Step by Step Tasks' section.

    Raises: ValueError if validation fails
    """
    content = spec_file.read_text()

    if not re.search(r"^## Step by Step Tasks", content, re.MULTILINE):
        raise ValueError(
            f"Markdown spec must have '## Step by Step Tasks' section: {spec_file}"
        )


def initialize_progress_file(spec_file: Path) -> Path:
    """
    Initialize progress file if it doesn't exist.

    Returns: Path to progress file
    """
    spec_name = spec_file.stem  # basename without extension
    progress_file = Path(f"{spec_name}-progress.txt")

    if not progress_file.exists():
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        content = f"""# Progress Log for {spec_name}
# Started: {timestamp}

"""
        progress_file.write_text(content)

    return progress_file


def check_json_completion(spec_file: Path) -> int:
    """
    Count incomplete stories in a JSON spec.

    Returns: Number of pending (incomplete) stories
    """
    try:
        content = spec_file.read_text()
        data = json.loads(content)
    except (json.JSONDecodeError, OSError) as e:
        log("ERROR", f"Failed to parse spec file: {e}")
        sys.exit(1)

    stories = data.get("stories", [])
    pending = 0

    for story in stories:
        status = story.get("status", "").lower()
        if status not in ("complete", "done"):
            pending += 1

    return pending


def check_markdown_completion(spec_file: Path) -> int:
    """
    Count incomplete tasks in a Markdown spec.

    Looks for h3 headers in the '## Step by Step Tasks' section
    that are NOT followed by '**Status:** complete'.

    Returns: Number of pending (incomplete) tasks
    """
    content = spec_file.read_text()
    lines = content.split("\n")

    in_tasks = False
    pending = 0
    prev_was_h3 = False

    for line in lines:
        # Check for entering Step by Step Tasks section
        if line.startswith("## Step by Step Tasks"):
            in_tasks = True
            continue

        # Check for exiting section (hit another h2)
        if in_tasks and line.startswith("## ") and not line.startswith("## Step by Step Tasks"):
            break

        if in_tasks:
            if line.startswith("### "):
                # Found a task header, assume incomplete until we check next line
                prev_was_h3 = True
                pending += 1
            elif prev_was_h3:
                # Check if this line marks completion
                if "**Status:**" in line and "complete" in line.lower():
                    pending -= 1
                prev_was_h3 = False

    return pending


def generate_json_prompt(spec_basename: str, progress_file: Path, completion_promise: str) -> str:
    """Generate the iteration prompt for JSON format specs."""
    return f"""# Ralph Wiggum Loop - Iteration Prompt

You are an autonomous AI agent working through a spec to complete all stories.

## Your Task

1. Read `{spec_basename}` to understand the stories and their status
2. Read `{progress_file}` to understand what has been learned in previous iterations
3. Select the highest-priority incomplete story that is not blocked
4. Implement the story completely
5. Update `{spec_basename}` to mark the story with `"status": "complete"` when done
6. Append learnings to `{progress_file}`

## Important Rules

- **One story per iteration**: Focus on completing one story fully before moving to the next
- **Update the spec file**: When a story is complete, set `"status": "complete"`
- **Append to progress file**: Document what you did, any issues encountered, and learnings
- **Stay focused**: Only work on stories in this spec, ignore other specs
- **Completion promise**: When all stories are complete, output exactly: `{completion_promise}`

## Story Priority Order

1. First, complete all P0 stories (highest priority)
2. Then, complete P1 stories
3. Then, complete P2 stories
4. Respect `blocked_by` dependencies - don't start a story until its dependencies are complete

## Verification

Before marking a story as complete:
- All acceptance criteria met
- Code compiles/lints without errors
- No obvious errors in the implementation

## Begin

Read `{spec_basename}` and `{progress_file}` now, then implement the next incomplete story."""


def generate_markdown_prompt(spec_basename: str, progress_file: Path, completion_promise: str) -> str:
    """Generate the iteration prompt for Markdown format specs."""
    return f"""# Ralph Wiggum Loop - Iteration Prompt

You are an autonomous AI agent working through a feature spec to complete all tasks.

## Your Task

1. Read `{spec_basename}` to understand the feature and the Step by Step Tasks
2. Read `{progress_file}` to understand what has been done in previous iterations
3. Find the first incomplete task (a task without `**Status:** complete` after its heading)
4. Implement that task completely
5. Update `{spec_basename}` to mark the task as complete by adding `**Status:** complete` on the line after the h3 heading
6. Append learnings to `{progress_file}`

## Important Rules

- **One task per iteration**: Focus on completing one task fully before moving to the next
- **Execute tasks in order**: Work through tasks from top to bottom as listed in the spec
- **Mark completion**: After the h3 task heading, add a line: `**Status:** complete`
- **Append to progress file**: Document what you did, any issues encountered, and learnings
- **Stay focused**: Only work on tasks in this spec
- **Completion promise**: When all tasks are complete, output exactly: `{completion_promise}`

## Task Status Format

When a task is incomplete, it looks like:
```
### Step 1: Create the database schema
- Create migrations for users table
- Add indexes
```

When you complete it, add the status line:
```
### Step 1: Create the database schema
**Status:** complete
- Create migrations for users table
- Add indexes
```

## Verification

Before marking a task as complete:
- All bullet points under the task are done
- Code compiles/lints without errors
- No obvious errors in the implementation

## Begin

Read `{spec_basename}` and `{progress_file}` now, then implement the next incomplete task."""


def check_completion_promise(output: str, promise: str) -> bool:
    """Check if the completion promise appears in the output."""
    return promise in output


def run_claude_iteration(prompt: str, progress_file: Path, iteration: int, summary_only: bool = False) -> tuple[int, str]:
    """
    Run a single Claude iteration with the given prompt.

    Args:
        prompt: The prompt to send to Claude
        progress_file: Path to progress file (unused, kept for compatibility)
        iteration: Iteration number
        summary_only: If True, suppress verbose Claude output (only capture, don't print)

    Returns: (exit_code, output)
    """
    cmd = ["claude", "--dangerously-skip-permissions", "--verbose", "-p", prompt]

    # Create temp file to capture output while also streaming it
    with tempfile.NamedTemporaryFile(mode="w", suffix=".txt", delete=False) as tmp:
        tmp_path = tmp.name

    try:
        # Run command with tee-like behavior
        process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            bufsize=1
        )

        output_lines = []
        with open(tmp_path, "w") as tmp_file:
            for line in process.stdout:
                # Only print if not in summary-only mode
                if not summary_only:
                    print(line, end="", flush=True)
                tmp_file.write(line)
                output_lines.append(line)

        process.wait()
        output = "".join(output_lines)

        return process.returncode, output
    finally:
        # Clean up temp file
        try:
            os.unlink(tmp_path)
        except OSError:
            pass


def commit_changes(spec_name: str, iteration: int) -> None:
    """Commit any uncommitted changes with an iteration-specific message."""
    # Check if there are uncommitted changes
    result = subprocess.run(
        ["git", "status", "--porcelain"],
        capture_output=True,
        text=True
    )

    if not result.stdout.strip():
        # No changes to commit
        return

    print("Committing changes...")

    # Stage all changes
    subprocess.run(["git", "add", "-A"], check=False)

    # Create commit message
    commit_message = f"""[{spec_name}] Ralph iteration {iteration}

Co-Authored-By: Claude <noreply@anthropic.com>"""

    # Commit changes (don't fail if commit fails)
    subprocess.run(
        ["git", "commit", "-m", commit_message],
        check=False,
        capture_output=True
    )


def run_ralph_loop(args: argparse.Namespace) -> int:
    """Main Ralph loop logic."""
    spec_file = Path(args.spec_file)
    max_iterations = args.max_iterations
    completion_promise = args.completion_promise

    # Detect and validate spec format
    try:
        spec_format = detect_spec_format(spec_file)
    except ValueError as e:
        log("ERROR", str(e))
        return 1

    # Validate spec file
    try:
        if spec_format == "json":
            validate_json_spec(spec_file)
        else:
            validate_markdown_spec(spec_file)
    except ValueError as e:
        log("ERROR", str(e))
        return 1

    # Initialize progress file
    progress_file = initialize_progress_file(spec_file)

    spec_basename = spec_file.name
    spec_name = spec_file.stem

    # Print header
    print("======================================")
    print("  Ralph Wiggum Loop")
    print("======================================")
    print()
    print(f"Spec file:          {spec_basename}")
    print(f"Spec format:        {spec_format}")
    print(f"Progress file:      {progress_file}")
    print(f"Max iterations:     {max_iterations}")
    print(f"Completion promise: {completion_promise}")
    print()

    iteration = 0

    while True:
        # Check max iterations
        if max_iterations > 0 and iteration >= max_iterations:
            print(f"Max iterations ({max_iterations}) reached.")
            break

        iteration += 1

        print("--------------------------------------")
        print(f"  Iteration {iteration} of {max_iterations}")
        print("--------------------------------------")

        # Check if all tasks are complete
        if spec_format == "json":
            pending = check_json_completion(spec_file)
        else:
            pending = check_markdown_completion(spec_file)

        if pending == 0:
            print("All stories complete! Exiting loop.")
            break

        print(f"Pending stories: {pending}")
        print()

        # Log iteration start
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        with open(progress_file, "a") as f:
            f.write(f"\n### Iteration {iteration} - {timestamp}\n")

        # Generate format-specific prompt
        if spec_format == "json":
            prompt = generate_json_prompt(spec_basename, progress_file, completion_promise)
        else:
            prompt = generate_markdown_prompt(spec_basename, progress_file, completion_promise)

        # Capture git status before iteration
        before_files = get_git_status()

        # Run Claude iteration
        print("Running Claude...")
        exit_code, output = run_claude_iteration(prompt, progress_file, iteration, args.summary_only)

        # Capture git status after iteration
        after_files = get_git_status()

        # Compute file changes during this iteration
        file_changes = diff_file_changes(before_files, after_files)

        if exit_code == 0:
            print("Iteration completed successfully")
            with open(progress_file, "a") as f:
                f.write("Status: Completed\n")

            # Check for completion promise
            if check_completion_promise(output, completion_promise):
                print()
                print(f"Completion promise detected: '{completion_promise}'")
                break
        else:
            print("Iteration failed")
            with open(progress_file, "a") as f:
                f.write("Status: Failed\n")

        # Commit any changes
        commit_changes(spec_name, iteration)

        # Generate and display iteration summary (unless disabled)
        if not args.no_summaries:
            print()
            summary = generate_iteration_summary(
                iteration=iteration,
                spec_format=spec_format,
                spec_file=spec_file,
                file_changes=file_changes,
                exit_code=exit_code
            )
            print(summary)
            print()

            # Append summary to progress file (without color codes)
            # Remove ANSI color codes for file storage
            summary_plain = summary
            for color_code in [GREEN, YELLOW, RED, BLUE, RESET]:
                summary_plain = summary_plain.replace(color_code, "")

            with open(progress_file, "a") as f:
                f.write("\n")
                f.write(summary_plain)
                f.write("\n")

        # Sleep between iterations
        time.sleep(2)

    # Final status
    print()
    print("======================================")
    print("  Ralph Loop Complete")
    print("======================================")

    if spec_format == "json":
        final_pending = check_json_completion(spec_file)
    else:
        final_pending = check_markdown_completion(spec_file)

    if final_pending == 0:
        print("SUCCESS: All stories completed!")
        return 0
    else:
        print(f"INCOMPLETE: {final_pending} stories remaining")
        return 1


def main() -> int:
    """Main entry point for ralph-loop."""
    args = parse_arguments()
    return run_ralph_loop(args)


if __name__ == "__main__":
    sys.exit(main())
